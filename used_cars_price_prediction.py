# -*- coding: utf-8 -*-
"""USED_CARS_PRICE_PREDICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ngRpze7YkKRWMy1IOUFAJ9ixP7BRIj0B
"""

from google.colab import drive;
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from scipy import stats
import missingno
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor,GradientBoostingRegressor,StackingRegressor,VotingRegressor
from sklearn.metrics import f1_score,mean_squared_error,r2_score,mean_absolute_error
from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.linear_model import LinearRegression,Ridge,Lasso,SGDRegressor
import xgboost as xgb
from sklearn.svm import SVR

data=pd.read_csv('drive/MyDrive/CAR_PRICE_PREDICTION/data.csv')
data.head(2)

data.shape

"""#### <b>MISSING VALUES ANALYSIS</b>


"""

data.replace(0,np.nan,inplace=True)
miss_per=round(data.isna().sum()*100/len(data),2)
print(f"{'Feature':{15}}{'Missing %'}\n{'='*25}")
print(miss_per)

missingno.bar(data,log=True,figsize=(15,5),fontsize=10)
plt.show()

missingno.matrix(data,fontsize=14)
plt.show()

"""#### <b>Summary:-</b><br>
- From the missing values pattern, it appears that the level of missingness is construct level which is generally referred when a case/example is partially filled. 
- Although, the column wise missing value percentage ranges from 2-5 % but row wise percentage is about 42 %, which is very high.
- **Rpm** contains 5.41% of missing values and removing these missing values row wise will result in significant loss of data. The original dataset (i.e before cleaning) has a **torque** feature in which the values are like 190Nm @ 500 rpm.That feature was splitted into two features i.e. torque and rpm.

#### <b>Handling Missing Values</b>
- **Rpm** feature can be dropped as it doesn't show any correlation with selling price.
- For other features with missing values, we need to focus on the following question:-
  - Is missingness low enough to delete ?
  - Is ignoring missing data worth it ?
  - Is the impact of missing values features,if included, significant in final prediction?
"""

data1=data.dropna()
round((data.shape[0]-data1.shape[0])*100/data.shape[0],2)

"""- Removing all the missing value cases, shrinks the dataset by **5.62 %**"""

# Splitting the dataset on the basis of valid and missing value cases
data_temp=data.fillna(-1)
data_valid=data_temp[data_temp['mileage']!=-1]
data_miss=data_temp[data_temp['mileage']==-1]
print(data_valid.shape)
print(data_miss.shape)

"""**Analyzing the difference in the distribution of selling price corresponding to valid and missing data**
- Is the difference significant ?
- Will removal of all the cases with missing data leads to biased results ?
"""

sns.distplot(np.log(data_valid['selling_price']),kde_kws = {'shade': True, 'linewidth': 3},label='Valid_values')
sns.distplot(np.log(data_miss['selling_price']),kde_kws = {'shade': True, 'linewidth': 3},label='Missing_values')
plt.yticks([])
plt.xticks([])
plt.title('Log (Selling_Price)')
plt.legend()
plt.show()

"""- By visualizing the log of selling price corrosponding to valid and missing values, it appears that there is a difference in the distribution.
- We need to determine whether this difference is significant or not by a statistical method.
- If the difference is significant i.e. p-value < alpha, then missingness can be classified as **Missing At Random (MAR)** otherwise **Missing Completely At Random (MCAR)**.

##### **Statistical Analysis for distribution:-**</br>
- We can perform t-test to check the difference in the distribution **BUT** t-test requires an assumption that data needs to be normally distributed.
- To check the normality assumption we can perform **Shapiro-Wilk** test in which :</br> Ho : Data is normally distributed</br> Ha : Data isn't normally distributed
"""

print(stats.shapiro(data_valid['selling_price']))
print(stats.shapiro(data_miss['selling_price']))
print('\n')
print(stats.shapiro(np.log(data_valid['selling_price'])))
print(stats.shapiro(np.log(data_miss['selling_price'])))

"""- The p-values in both Log and without Log of data is close to zero.Thus rejecting the null hypothesis.Therefore can't perform t-test.
- Let's try **kolmogorov-smirnov test** which checks the null hypothesis that two samples come from the same distribution
"""

# kolmogorov-smirnov test 
stats.ks_2samp(data_valid['selling_price'],data_miss['selling_price'])

"""- **The pvalue is almost negligible, giving us strong evidence for rejecting the null hypothesis i.e. distributions are not from same sample** <br>

##### **SKEWNESS & KURTOSIS COMPARISION OF FEATURES**
"""

print('SKEWNESS','Valid'.rjust(13),'Missing'.rjust(13),\
      'KURTOSIS'.rjust(15),'Valid'.rjust(13),'Missing'.rjust(13),'\n','='*80)
columns=['selling_price', 'km_driven', 'mileage', 'engine', 'max_power', 'seats',
       'torque']
for i in columns:
    print(f'{i:{15}}{round(data_valid[i].skew(),2):{7}}{round(data_miss[i].skew(),2):{12}}\
          {i:{15}}{round(data_valid[i].kurtosis(),2):{7}}{round(data_miss[i].kurtosis(),2):{12}}')

"""##### **Summary:**
- Since the data is skewed, we can't perform t-test as normality assumption is violated.
- From kolmogorov-smirnov test, we infer that removing all the cases with missing values can create some biasedness in prediction.
- Removing all the missing value cases,even though percentage looks small, might not be beneficial.
- Therefore, we need imputation strategies for missing values in mileage,engine,max_power,seats and torque.
"""

# Creating a new feature years_old and Dropping name and rpm.
import datetime
current_date=datetime.datetime.now()
data['years_old']=data['year'].apply(lambda x:current_date.year-x)
data1=data.drop(['name','year','rpm'],axis=1)

data1.head()

data1.seller_type.unique()

"""#### **HEATMAP**"""

plt.figure(figsize=(15,5))
sns.heatmap(data1.corr(),annot=True,fmt='.2g')
plt.show()

"""#### **MISSING VALUES IMPUTATION STRATEGY:**</br>
- Missing values are present in **mileage,engine,max_power,seats,torque and rpm.**
- First, we will split dataset into two parts i.e one with complete cases and another with incomplete cases.
- Then Complete cases will be used for training purpose to impute the values into incomplete cases.
- The **max_power** has strong positive correlation of 0.75 with selling price, 0.7 with engine and negative correlation with mileage and years_old.

"""

data_temp=data1.fillna(-1)
data_valid=data_temp[data_temp['mileage']!=-1]
data_miss=data_temp[data_temp['mileage']==-1]
print(data_valid.shape)
print(data_miss.shape)

"""##### **1) Max_power**</br>
Max power has strong positive correlation of 0.75 with **selling price** and negative correlation with **years_old**. (#these are complete features)
"""

X=data_valid[['selling_price','years_old']]
y=data_valid['max_power']
rf=RandomForestRegressor(n_estimators=50)
rf.fit(X,y)
y_pred=rf.predict(X)
print('R2_score =',round(rf.score(X,y),2))
print('RMSE =',round(np.sqrt(mean_squared_error(y_pred,y)),2))
#imputing max_power missing values
max_pow_miss=rf.predict(data_miss[['selling_price','years_old']])
data_miss['max_power']=max_pow_miss

"""##### **2) Engine**</br>

"""

X=data_valid[['selling_price','max_power','km_driven']]
y=data_valid['engine']
rf=RandomForestClassifier(n_estimators=50)
rf.fit(X,y)
y_pred=rf.predict(X)
print('R2_score =',round(rf.score(X,y),2))
print('RMSE =',round(np.sqrt(mean_squared_error(y_pred,y)),2))
data_miss['engine']=rf.predict(data_miss[['selling_price','max_power','km_driven']])

"""#### **3) Mileage**"""

X=data_valid[['selling_price','engine','max_power','years_old']] #not including mileage since it is missing
y=data_valid['mileage'].astype('int')
rf=RandomForestRegressor(n_estimators=50)
rf.fit(X,y)
y_pred=rf.predict(X)
print('R2_score =',round(rf.score(X,y),2))
print('RMSE =',round(np.sqrt(mean_squared_error(y_pred,y)),2)) 
data_miss['mileage']=rf.predict(data_miss[['selling_price','engine','max_power','years_old']])

"""##### **4) Seats**

"""

X=data_valid[['engine','mileage','km_driven']] #not including mileage since it is missing
y=data_valid['seats']
rf=RandomForestClassifier(n_estimators=50)
rf.fit(X,y)
y_pred=rf.predict(X)
print('R2_score =',round(rf.score(X,y),2))
print('RMSE =',round(np.sqrt(mean_squared_error(y_pred,y)),2)) 
data_miss['seats']=rf.predict(data_miss[['engine','mileage','km_driven']]).astype('int')

"""##### **5) Torque**

"""

X=data_valid[['engine','max_power']] #not including mileage since it is missing
y=data_valid['torque']
rf=RandomForestRegressor(n_estimators=50)
rf.fit(X,y)
y_pred=rf.predict(X)
print('R2_score =',round(rf.score(X,y),2))
print('RMSE =',round(np.sqrt(mean_squared_error(y_pred,y)),2)) 
data_miss['torque']=rf.predict(data_miss[['engine','max_power']])

"""**Concatinated dataset and shuffled. All missing values imputed.**"""

# Concatinating dataset after imputing values
data2=pd.concat([data_valid,data_miss],ignore_index=True)
data2=data2.sample(frac=1).reset_index(drop=True)
data2.head()

# Dropping duplicate entries
#data2.drop_duplicates(inplace=True)
#print(data2.shape)

"""### **Outliers Analysis**</br>"""

fig, ax = plt.subplots(2, 4)
sns.boxplot(data2['selling_price'],ax = ax[0,0])
sns.boxplot(data2['km_driven'],ax = ax[0,1])
sns.boxplot(data2['mileage'],ax = ax[0,2])
sns.boxplot(data2['engine'],ax = ax[0,3])
sns.boxplot(data2['max_power'],ax = ax[1,0])
sns.boxplot(data2['seats'],ax = ax[1,1])
sns.boxplot(data2['torque'],ax = ax[1,2])
sns.boxplot(data2['years_old'],ax = ax[1,3])
fig.set_figheight(7)
fig.set_figwidth(22)
plt.show()

data[data['selling_price']==data.selling_price.max()]

"""The actual price of brand new <b>"Volvo XC90 T8 Excellence BSIV"</b> is about 1.31 crore, so this selling price looks valid. Although, from the box plot it appears as an outlier but removing a valid outlier doesn't feels like a good idea."""

q1,q3=np.percentile(data2['km_driven'].values,[25,75])
upper_fence=q3+1.5*(q3-q1)
lower_fence=q1-1.5*(q3-q1)
x=data2[data2['km_driven']>upper_fence]
print('Pearson correlation=',stats.pearsonr(x['km_driven'],x['selling_price'])[0])
data2['km_driven'][data2['km_driven']>upper_fence]=upper_fence

"""Since pearson correlation is negligible, the outliers are assigned with upper_fence value."""

q1,q3=np.percentile(data2['mileage'].values,[25,75])
upper_fence=q3+1.5*(q3-q1)
lower_fence=q1-1.5*(q3-q1)
x=data2[data2['mileage']>upper_fence]
x.sort_values(by='mileage',ascending=False)

"""One thing is common here, that all the vehicles,having high mileage, run on CNG fuel. The highest value i.e 42.0 kmpl is correct and verified by internet search. All these values will be kept as it is."""

q1,q3=np.percentile(data2['engine'].values,[25,75])
upper_fence=q3+1.5*(q3-q1)
lower_fence=q1-1.5*(q3-q1)
x=data2[data2['engine']>upper_fence]
data2.sort_values(by='engine',ascending=False).head()

"""Outlier values in **engine, max_power and seats** are valid values. These values will not be removed"""

data.sort_values(by='torque',ascending=False).head(2)

"""The actual torque of **Ford Endeavour** is **380Nm @ 2500rpm** and **Honda Jazz 110 (11.2) @ 4800**. So, imputing the correct values."""

data2['torque'][data2['torque']==38038.7]=380
data2['torque'][data2['torque']==11011.2]=110
data2['torque'][data2['torque']==-1]=58.560
data2['max_power'][data2['max_power']==-1]=38.840

data2.sort_values(by='years_old',ascending=False).head(2)

fig,ax=plt.subplots(1,2)
sns.barplot(x='fuel',y='selling_price',hue='fuel',data=data2,ax=ax[0])
sns.countplot(x='fuel',hue='fuel',data=data2,ax=ax[1])
fig.set_figwidth(15)
fig.set_figheight(5)
plt.show()

fig,ax=plt.subplots(1,2)
sns.barplot(x='seller_type',y='selling_price',hue='seller_type',data=data2,ax=ax[0])
sns.countplot(x='seller_type',data=data2,ax=ax[1],dodge=True)
fig.set_figwidth(15)
fig.set_figheight(5)
fig.set
plt.show()

fig,ax=plt.subplots(1,2)
sns.barplot(x='transmission',y='selling_price',hue='fuel',data=data2,ax=ax[0])
sns.countplot(x='transmission',hue='fuel',data=data2,ax=ax[1])
fig.set_figwidth(15)
fig.set_figheight(5)
plt.show()

fig,ax=plt.subplots(1,2)
plt.xticks(rotation=45)
sns.barplot(x='owner',y='selling_price',data=data2,ax=ax[0])
sns.countplot(x='owner',data=data2,ax=ax[1])
plt.xticks(rotation=45)
fig.set_figwidth(15)
fig.set_figheight(5)
plt.show()

fig,ax=plt.subplots(1,2)
plt.xticks(rotation=45)
sns.barplot(x='years_old',y='selling_price',data=data2,ax=ax[0])
sns.countplot(x='years_old',data=data2,ax=ax[1])
plt.xticks(rotation=45)
fig.set_figwidth(18)
fig.set_figheight(5)
plt.show()

"""#### **Maping of Categorical Variables**"""

mydict1={'Manual':1,'Automatic':2}
mydict2={'Diesel':4,'Petrol':3,'LPG':2,'CNG':1}
mydict3={'First Owner':4, 'Second Owner':3, 'Third Owner':2,'Fourth & Above Owner':1, 'Test Drive Car':5}
mydict4={'Individual':1, 'Dealer':3, 'Trustmark Dealer':2}

data2['transmission']=data2['transmission'].map(mydict1)
data2['fuel']=data2['fuel'].map(mydict2)
data2['owner']=data2['owner'].map(mydict3)
data2['seller_type']=data2['seller_type'].map(mydict4)

data2.head()

"""#### **Multicollinearity Check**"""

from statsmodels.stats.outliers_influence import variance_inflation_factor

# calculating VIF for each feature
vif_data = pd.DataFrame()
vif_data["data2"] = data2.columns
vif_data["VIF_1"] = [variance_inflation_factor(data2.values, i) for i in range(len(data2.columns))]
vif_data.sort_values('VIF_1',ascending=False,ignore_index=True)

"""Multicollinearity level in most of the features are very high. Let's scale these features and try VIF once more."""

# Scaling all the features except Selling_price
scaled=StandardScaler().fit_transform(data2[['km_driven','mileage','engine','max_power','seats','torque','years_old','fuel','seller_type','transmission','owner']])

data2_scaled=data2.copy()
data2_scaled[['km_driven','mileage','engine','max_power','seats','torque','years_old','fuel','seller_type','transmission','owner']]=scaled

data2_scaled.head()

vif_data["data2_scaled"] = data2_scaled.columns
vif_data["VIF_2"] = [variance_inflation_factor(data2_scaled.values, i) for i in range(len(data2_scaled.columns))]
vif_data.sort_values('VIF_2',ascending=False,ignore_index=True)

fig, axes = plt.subplots(1,2,figsize=(15,4))
axes[0].set_title('selling_price')
sns.distplot(data2['selling_price'].values.reshape(-1,1),ax=axes[0],kde_kws = {'shade': True, 'linewidth': 3,'color':'black','fill':True},color='blue')
axes[1].set_title('log-transformation')
sns.distplot(np.log(data2['selling_price'].values.reshape(-1,1)),ax=axes[1],kde_kws = {'shade': True, 'linewidth': 3,'color':'black','fill':True},color='blue')
plt.show()

data2_scaled['selling_price']=np.log(data2_scaled['selling_price'])

data2_scaled.head()

X=data2_scaled.drop('selling_price',axis=1)
y=data2_scaled['selling_price']

# OLS
import statsmodels.api as sm
X= sm.add_constant(X)
result = sm.OLS(y,X).fit()
# printing the summary table
print(result.summary())

"""#### **Modelling**"""

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)

# LINEAR REGRESSION
def linear_regression(X_train,y_train,X_test,y_test):
  y_pred=LinearRegression().fit(X,y).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#RIDGE
def ridge_regression(X_train,y_train,X_test,y_test):
  y_pred=Ridge(alpha=0.5).fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#LASSO
def lasso_regression(X_train,y_train,X_test,y_test):
  y_pred=Lasso(alpha=0.5).fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#KNN
def knn_regression(X_train,y_train,X_test,y_test):
  y_pred=KNeighborsRegressor(n_neighbors=2).fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#RANDOM FOREST
def randomforest_reg(X_train,y_train,X_test,y_test):
  y_pred=RandomForestRegressor(max_depth=3).fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))
#BAGGING
def bagging_reg(X_train,y_train,X_test,y_test):
  y_pred=BaggingRegressor(base_estimator=SVR(),n_estimators=10, random_state=0).fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#ADABOOST
def adaboost_reg(X_train,y_train,X_test,y_test):
  y_pred=AdaBoostRegressor().fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#XGBOOST
def xgboost_reg(X_train,y_train,X_test,y_test):
  y_pred=xgb.XGBRFRegressor(objective='reg:linear',n_estimators=10).fit(X_train,y_train).predict(X_test)
  return (mean_absolute_error(y_test,y_pred))

#SGDRegressor
def sgd_reg(X_train,y_train,X_test,y_test):
  y_pred=SGDRegressor().fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#EXTRA_TREES
def extra_trees_reg(X_train,y_train,X_test,y_test):
  y_pred=ExtraTreesRegressor().fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

#GRADIENT BOOSTING
def gradientB_reg(X_train,y_train,X_test,y_test):
  y_pred=GradientBoostingRegressor().fit(X_train,y_train).predict(X_test)
  return (mean_squared_error(y_test,y_pred))

def model(X,y,test_size):
  #X=dataset.drop('selling_price',axis=1)
  #y=dataset['selling_price']
  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=test_size,shuffle=True,random_state=12)
  #LINEAR REGRESSION
  result=linear_regression(X_train,y_train,X_test,y_test)
  #RIDGE
  result1=ridge_regression(X_train,y_train,X_test,y_test)
  #LASSO
  result2=lasso_regression(X_train,y_train,X_test,y_test)
  #KNN
  result3=knn_regression(X_train,y_train,X_test,y_test)
  #RANDOM FOREST
  result4=randomforest_reg(X_train,y_train,X_test,y_test)
  #BAGGING
  result5=bagging_reg(X_train,y_train,X_test,y_test)
  #ADABOOST
  result6=adaboost_reg(X_train,y_train,X_test,y_test)
  #XGBOOST
  result7=xgboost_reg(X_train,y_train,X_test,y_test)
  #SGDRegressor
  result8=sgd_reg(X_train,y_train,X_test,y_test)
  #EXTRA_TREES
  result9=extra_trees_reg(X_train,y_train,X_test,y_test)
  #GRADIENT BOOSTING
  result10=gradientB_reg(X_train,y_train,X_test,y_test)
  print('LINEAR: ',result,'\n','RIDGE: ',result1,'\n','LASSO:',result2,'\n','KNN: ',result3,'\n',
        'RANDOMFOREST:',result4,'\n','BAGGING:',result5,'\n','ADABOOST:',result6,'\n','XGBOOST:',result7,'\n','SGDReg:',result8,'\n',
        'EXTRA_TREES:',result9,'\n','GRADIENT_BOOSTING',result10)

model(X,y,0.3)

"""ExtraTreesRegressor and Gradient Boosting has least mean square error. Therefore adopting these algorithms for further analysis."""

#performace metric
def metric(y_pred,y_test):
  y_pred1=np.exp(y_pred)
  y_test1=np.exp(y_test)
  print('MSE_log      =',round(mean_squared_error(y_pred,y_test),3))
  print('RMSE_log     =',round(np.sqrt(mean_squared_error(y_pred,y_test)),3))
  print('MAE_log      =',round(mean_absolute_error(y_pred,y_test),3))
  print('r2_score     =',round(r2_score(y_pred,y_test),4))
  print('MSE_exp      =',round(mean_squared_error(y_pred1,y_test1),3))
  print('RMSE_exp     =',round(np.sqrt(mean_squared_error(y_pred1,y_test1)),3))
  print('MAE_exp      =',round(mean_absolute_error(y_pred1,y_test1),3))
  print('r2_score_exp =',round(r2_score(y_pred1,y_test1),3))

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)
y_pred=ExtraTreesRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)
y_pred=ExtraTreesRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

y_pred=GradientBoostingRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

y_pred=GradientBoostingRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

"""ExtraTreesRegression is performing better than GradientBoostingRegressor"""

fig,ax=plt.subplots(1,2)
sns.distplot((np.exp(y_test)-np.exp(y_pred)),ax=ax[0])
plt.scatter(np.exp(y_test),np.exp(y_pred))
fig.set_figwidth(15)
fig.set_figheight(4)
plt.show()

per=np.percentile(data2['selling_price'].values,[5,25,50,75,85,95,99])
per

def vals(x):
  if x<per[0]:
    return 5
  elif per[0]<=x<per[1]:
    return 25
  elif per[1]<=x<per[2]:
    return 50
  elif per[2]<=x<per[3]:
    return 75
  elif per[3]<=x<per[4]:
    return 85
  elif per[4]<=x<per[5]:
    return 95
  else:
    return 99

"""Adding a percentile feature that classify selling price and also give weightage."""

data2_scaled['percentile']=data2['selling_price'].apply(lambda x:vals(x))

data2_scaled.head()

X=data2_scaled.drop('selling_price',axis=1)
y=data2_scaled['selling_price']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)

y_pred=ExtraTreesRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

scaled=StandardScaler().fit_transform(data2[['km_driven','mileage','engine','max_power','seats','torque','years_old','fuel','seller_type','transmission','owner']])
data2_scaled_mm=data2.copy()
data2_scaled_mm[['km_driven','mileage','engine','max_power','seats','torque','years_old','fuel','seller_type','transmission','owner']]=scaled

data2_scaled_mm['selling_price']=np.log(data2_scaled_mm['selling_price'])
data2_scaled_mm['percentile']=data2['selling_price'].apply(lambda x:vals(x))
data2_scaled_mm['percentile']=StandardScaler().fit_transform(data2_scaled_mm['percentile'].values.reshape(-1,1))

data2_scaled_mm.head()

"""#### **FINAL MODEL**"""

X=data2_scaled_mm.drop('selling_price',axis=1)
y=data2_scaled_mm['selling_price']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)
y_pred=ExtraTreesRegressor().fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

model=ExtraTreesRegressor()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
metric(y_pred,y_test)

X=data2_scaled_mm.drop('selling_price',axis=1)
y=data2_scaled_mm['selling_price']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True,random_state=12)
y_pred=ExtraTreesRegressor(n_estimators=60, n_jobs=4, min_samples_split=9,
                            min_samples_leaf=10).fit(X_train,y_train).predict(X_test)
metric(y_pred,y_test)

from xgboost import XGBRegressor

xgb=XGBRegressor()
xgb.fit(X_train,y_train)
y_pred=xgb.predict(X_test)
metric(y_pred,y_test)

temp=pd.DataFrame()
temp['actual']=np.exp(y_test)
temp['predict']=np.exp(y_pred)
temp['diff']=round((np.exp(y_test)-np.exp(y_pred))*100/np.exp(y_test),2)

x=temp.head(20)

x.plot(kind='bar',figsize=(20,4))

x1=temp.sort_values(by='diff',ascending=False)
x2=x1[['actual','predict']].head(50)
x2.plot(kind='bar',figsize=(20,4))

import pickle
file = open("file.pkl", "wb") # opening a new file in write mode
pickle.dump(model, file) # dumping created model into a pickle file

pickle.load(open('file.pkl','rb'))

import joblib

joblib.dump(model,'car_model.pkl')

"""### **SUMMARY**:
Finally, after testing various models the ExtraTreesRegressor and XGBRegressor, with little hypertuning, performed well.The R2 score of both the models comes out to be **0.97**.

### **Future scope**:
The dataset lacks **Actual price** column, presence of which could improve the performance and reliability of the model significantly.Since, we all know that the moment car comes out of a showroom, its price starts to depreciate.Perhaps, we could use this factor in determining the current worth of a car.

"""

